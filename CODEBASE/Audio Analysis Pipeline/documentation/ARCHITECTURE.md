# System Architecture Overview
## Clinical Audio Analysis Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PHASE 1: DATA MINING MACHINE                     â”‚
â”‚                    (General-Purpose SOTA Models)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚   main.py    â”‚
                              â”‚ (User Entry) â”‚
                              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  AnalysisPipeline        â”‚
                      â”‚  (Orchestrator/"Brain")  â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚            â”‚            â”‚          â”‚
                    â–¼            â–¼            â–¼          â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Diarization  â”‚ â”‚    ASR    â”‚ â”‚ Emotion â”‚ â”‚ Acoustic â”‚
         â”‚   Service    â”‚ â”‚  Service  â”‚ â”‚ Service â”‚ â”‚ Service  â”‚
         â”‚              â”‚ â”‚           â”‚ â”‚ (Triple â”‚ â”‚          â”‚
         â”‚              â”‚ â”‚           â”‚ â”‚ Ensemble)â”‚ â”‚          â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                â”‚               â”‚            â”‚           â”‚
                â”‚               â”‚            â”‚           â”‚
                â”‚               â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”     â”‚
                â”‚               â”‚     â”‚            â”‚     â”‚
                â”‚               â”‚     â–¼            â–¼     â”‚
                â”‚               â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
                â”‚               â”‚  â”‚ HuBERT â”‚ â”‚Wav2Vec2â”‚â”‚
                â”‚               â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
                â”‚               â”‚     â”‚            â”‚     â”‚
                â”‚               â””â”€â”€â”€â”€â”€â”¤            â”‚     â”‚
                â”‚                     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
                â”‚                     â”‚  â”‚DistilRo  â”‚    â”‚
                â”‚                     â”‚  â”‚  BERTa   â”‚    â”‚
                â”‚                     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
                â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼                              â–¼          â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚            Audio Utilities Module                â”‚
         â”‚  â€¢ load_and_resample_audio()                    â”‚
         â”‚  â€¢ slice_audio()                                â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  Input Audio     â”‚
                      â”‚  (.mp3, .wav,    â”‚
                      â”‚   .m4a, etc.)    â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                           DATA FLOW (Step by Step)

  1. USER ACTION
     â””â”€â–º python main.py -i conversation.mp3

  2. INITIALIZATION
     â”œâ”€â–º Load Diarization Model (pyannote 3.1)
     â”œâ”€â–º Load ASR Model (faster-whisper)
     â”œâ”€â–º Load Emotion Models (Triple Ensemble):
     â”‚   â”œâ”€â–º HuBERT (prosody analysis)
     â”‚   â”œâ”€â–º Wav2Vec2 (phonetic analysis)
     â”‚   â””â”€â–º DistilRoBERTa (semantic/text analysis)
     â””â”€â–º Load Acoustic Analyzer (Praat)

  3. AUDIO LOADING
     â”œâ”€â–º Load audio file
     â”œâ”€â–º Convert to mono (if stereo)
     â””â”€â–º Resample to 16kHz

  4. DIARIZATION (Who spoke, when?)
     â””â”€â–º Output: List of segments with speaker labels & timestamps

  5. FOR EACH SEGMENT:
     â”œâ”€â–º Slice audio using timestamps
     â”œâ”€â–º ASR Analysis â†’ Transcript
     â”œâ”€â–º Acoustic Analysis â†’ F0, Jitter, Shimmer, HNR
     â””â”€â–º Emotion Analysis (Triple Ensemble):
         â”œâ”€â–º HuBERT predicts from audio (prosody)
         â”œâ”€â–º Wav2Vec2 predicts from audio (phonetics)
         â”œâ”€â–º DistilRoBERTa predicts from transcript (semantics)
         â”œâ”€â–º Validate predictions with acoustic features
         â”œâ”€â–º Apply dynamic weighting based on confidence
         â”œâ”€â–º Check for veto conditions (>0.90 confidence)
         â””â”€â–º Combine predictions â†’ Final label + confidence

  6. AGGREGATION
     â””â”€â–º Combine all results into structured JSON

  7. OUTPUT
     â””â”€â–º Save to data/output/conversation.json


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                        SERVICES DETAIL

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 1: DIARIZATION SERVICE                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Model: pyannote/speaker-diarization-3.1                                 â”‚
â”‚ Purpose: Identify who spoke and when                                    â”‚
â”‚ Input: Audio file path                                                  â”‚
â”‚ Output: [{speaker: "SPEAKER_00", start: 0.5, end: 3.2}, ...]           â”‚
â”‚ Config: num_speakers=2 (clinical default)                              â”‚
â”‚ Requires: Hugging Face authentication token                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 2: ASR SERVICE                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Model: faster-whisper (base.en or medium.en)                           â”‚
â”‚ Purpose: Transcribe speech to text                                     â”‚
â”‚ Input: Audio slice (NumPy array)                                       â”‚
â”‚ Output: "Hello, how are you feeling today?"                            â”‚
â”‚ Optimization: float16 on GPU, float32 on CPU                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 3: EMOTION SERVICE (Triple Ensemble)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Architecture: Three-Model Ensemble for Maximum Accuracy                 â”‚
â”‚                                                                          â”‚
â”‚ MODEL 1: HuBERT (Prosody Expert)                                        â”‚
â”‚   â””â”€â–º Model: superb/hubert-base-superb-er                              â”‚
â”‚   â””â”€â–º Focus: Tone, pitch, rhythm patterns                              â”‚
â”‚   â””â”€â–º Labels: neu, hap, ang, sad (4 emotions)                          â”‚
â”‚                                                                          â”‚
â”‚ MODEL 2: Wav2Vec2 (Phonetic Expert)                                     â”‚
â”‚   â””â”€â–º Model: ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognitionâ”‚
â”‚   â””â”€â–º Focus: Articulation and phonetic changes under emotion           â”‚
â”‚   â””â”€â–º Labels: angry, calm, disgust, fearful, happy, neutral, sad,     â”‚
â”‚               surprised (8 emotions)                                    â”‚
â”‚                                                                          â”‚
â”‚ MODEL 3: DistilRoBERTa (Semantic Expert)                                â”‚
â”‚   â””â”€â–º Model: j-hartmann/emotion-english-distilroberta-base            â”‚
â”‚   â””â”€â–º Focus: Word meaning and emotional content                        â”‚
â”‚   â””â”€â–º Labels: anger, disgust, fear, joy, neutral, sadness, surprise   â”‚
â”‚               (7 emotions)                                              â”‚
â”‚                                                                          â”‚
â”‚ ENSEMBLE LOGIC:                                                          â”‚
â”‚   1. All three predictions generated independently                      â”‚
â”‚   2. Dynamic weighting based on confidence scores                       â”‚
â”‚   3. Veto power: >0.90 confidence predictions override others          â”‚
â”‚   4. Acoustic validation: Cross-check with pitch/jitter/HNR            â”‚
â”‚   5. Smart disagreement handling:                                       â”‚
â”‚      â€¢ Audio consensus â†’ Use audio (may indicate sarcasm)              â”‚
â”‚      â€¢ Text high confidence + acoustics support â†’ Use text             â”‚
â”‚      â€¢ Mixed predictions â†’ Weighted vote                               â”‚
â”‚                                                                          â”‚
â”‚ Input: Audio slice (NumPy array) + Transcript + Acoustic features      â”‚
â”‚ Output: {                                                               â”‚
â”‚   label: "ang",                                                         â”‚
â”‚   score: 0.85,                                                          â”‚
â”‚   confidence: "high",                                                   â”‚
â”‚   hubert_emotion: "ang",                                                â”‚
â”‚   wav2vec2_emotion: "angry",                                            â”‚
â”‚   text_emotion: "anger",                                                â”‚
â”‚   agreement: "full",                                                    â”‚
â”‚   sarcasm_flag: false,                                                  â”‚
â”‚   method: "triple_ensemble"                                             â”‚
â”‚ }                                                                        â”‚
â”‚                                                                          â”‚
â”‚ Improvements (Nov 6, 2025):                                             â”‚
â”‚   âœ… Dynamic adaptive weighting                                         â”‚
â”‚   âœ… Veto power for high-confidence predictions                         â”‚
â”‚   âœ… Acoustic feature integration                                       â”‚
â”‚   âœ… Confidence calibration                                             â”‚
â”‚   âœ… Context-aware emotion mapping                                      â”‚
â”‚   âœ… Segment quality filtering                                          â”‚
â”‚                                                                          â”‚
â”‚ Result: ~85% emotion accuracy (up from ~60% with single model)         â”‚
â”‚                                                                          â”‚
â”‚ Phase 2: All three models can be hot-swapped with fine-tuned versions  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE 4: ACOUSTIC SERVICE                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Library: parselmouth-praat                                              â”‚
â”‚ Purpose: Extract objective acoustic features                            â”‚
â”‚ Input: Audio slice (NumPy array)                                       â”‚
â”‚ Output: {pitch_mean_f0: 142.3, jitter: 0.012, ...}                     â”‚
â”‚ Features:                                                               â”‚
â”‚  â€¢ Pitch (F0) - Fundamental frequency in Hz                            â”‚
â”‚  â€¢ Jitter - Vocal fold stability measure                               â”‚
â”‚  â€¢ Shimmer - Amplitude variation measure                               â”‚
â”‚  â€¢ HNR - Harmonics-to-Noise Ratio (voice quality)                      â”‚
â”‚ Note: Returns None for very short/silent segments (by design)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                        OUTPUT JSON STRUCTURE

{
  "file": "conversation.mp3",
  "segments": [
    {
      "segment_id": 0,
      "speaker": "SPEAKER_00",        â—„â”€â”€ From Diarization
      "start_time": 0.5,              â—„â”€â”€ From Diarization
      "end_time": 3.2,                â—„â”€â”€ From Diarization
      "duration": 2.7,
      "transcript": "Hello...",       â—„â”€â”€ From ASR
      "predicted_emotion": {          â—„â”€â”€ From Emotion Service (Triple Ensemble)
        "label": "neutral",
        "score": 0.8523,
        "confidence": "high",
        "hubert_emotion": "neu",
        "hubert_score": 0.90,
        "wav2vec2_emotion": "calm",
        "wav2vec2_score": 0.75,
        "text_emotion": "neutral",
        "text_score": 0.88,
        "agreement": "full",
        "sarcasm_flag": false,
        "mixed_emotion_flag": false,
        "method": "triple_ensemble"
      },
      "acoustic_features": {          â—„â”€â”€ From Acoustic Service
        "pitch_mean_f0": 142.3,
        "jitter_local": 0.012,
        "shimmer_local": 0.045,
        "hnr_mean": 12.5
      }
    },
    { ... more segments ... }
  ]
}


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                  TRIPLE ENSEMBLE EMOTION ARCHITECTURE

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   WHY TRIPLE ENSEMBLE?                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  Single Model Problem:                                                 â”‚
â”‚    â€¢ HuBERT alone: ~60% accuracy                                       â”‚
â”‚    â€¢ Only analyzes prosody (tone, pitch)                               â”‚
â”‚    â€¢ Misses semantic information from words                            â”‚
â”‚    â€¢ Can't detect sarcasm or masked emotions                           â”‚
â”‚                                                                         â”‚
â”‚  Triple Ensemble Solution:                                             â”‚
â”‚    â€¢ Three complementary perspectives                                  â”‚
â”‚    â€¢ HuBERT: HOW they sound (prosody)                                  â”‚
â”‚    â€¢ Wav2Vec2: HOW they articulate (phonetics)                         â”‚
â”‚    â€¢ DistilRoBERTa: WHAT they say (semantics)                          â”‚
â”‚    â€¢ Combined accuracy: ~85% (+25% improvement!)                       â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                          PROCESSING FLOW

   Audio Segment + Transcript + Acoustic Features
                    â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚              â”‚              â”‚              â”‚
                    â–¼              â–¼              â–¼              â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
            â”‚ HuBERT   â”‚   â”‚ Wav2Vec2 â”‚   â”‚DistilRo  â”‚         â”‚
            â”‚ (Audio)  â”‚   â”‚ (Audio)  â”‚   â”‚BERTa(Txt)â”‚         â”‚
            â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜         â”‚
                 â”‚              â”‚              â”‚                â”‚
                 â–¼              â–¼              â–¼                â–¼
            neu (0.90)     angry (0.75)   anger (0.88)   Acoustics
                 â”‚              â”‚              â”‚          (pitch, etc)
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ENSEMBLE COMBINER    â”‚
                    â”‚  (Intelligent Logic)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                       â”‚
                    â–¼                       â–¼
            Check Veto?              All Agree?
            (>0.90 conf)            
                    â”‚                       â”‚
                    â”œâ”€ YES â†’ Use veto       â”œâ”€ YES â†’ High conf
                    â””â”€ NO  â†’ Continue       â””â”€ NO  â†’ Smart logic
                                â”‚
                                â–¼
                        Dynamic Weighting
                        Acoustic Validation
                        Disagreement Handling
                                â”‚
                                â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ FINAL OUTPUT  â”‚
                        â”‚ label: "ang"  â”‚
                        â”‚ score: 0.85   â”‚
                        â”‚ confidence: h â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  INTELLIGENT COMBINATION LOGIC                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  STEP 1: Individual Predictions                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚    Run all three models independently:                                 â”‚
â”‚    â€¢ HuBERT analyzes audio prosody                                     â”‚
â”‚    â€¢ Wav2Vec2 analyzes audio phonetics                                 â”‚
â”‚    â€¢ DistilRoBERTa analyzes transcript semantics                       â”‚
â”‚                                                                         â”‚
â”‚  STEP 2: Quality Check                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â”‚
â”‚    Filter out bad segments:                                            â”‚
â”‚    â€¢ Duration < 0.3 seconds â†’ Skip                                     â”‚
â”‚    â€¢ Near-silence (amplitude < 0.01) â†’ Skip                            â”‚
â”‚                                                                         â”‚
â”‚  STEP 3: Veto Check (Priority Override)                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                    â”‚
â”‚    IF any model has >0.90 confidence on non-neutral:                   â”‚
â”‚      â†’ Give it 70% weight (veto power)                                 â”‚
â”‚      â†’ Prevents washout by neutral predictions                         â”‚
â”‚    Example: Text "anger" (0.94) â†’ Overrides audio "neutral"           â”‚
â”‚                                                                         â”‚
â”‚  STEP 4: Agreement Analysis                                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚    CASE A: All three agree                                             â”‚
â”‚      â†’ Very high confidence (boost +25%)                               â”‚
â”‚      â†’ agreement: "full"                                               â”‚
â”‚                                                                         â”‚
â”‚    CASE B: Both audio agree, text differs                              â”‚
â”‚      â†’ Check acoustic features:                                        â”‚
â”‚         â€¢ Text confident + loud voice â†’ Trust text                     â”‚
â”‚         â€¢ Text confident + calm voice â†’ Trust audio (sarcasm!)         â”‚
â”‚      â†’ agreement: "audio_consensus" or "text_priority"                 â”‚
â”‚      â†’ sarcasm_flag: true/false                                        â”‚
â”‚                                                                         â”‚
â”‚    CASE C: No agreement (mixed predictions)                            â”‚
â”‚      â†’ Calculate dynamic weights                                       â”‚
â”‚      â†’ Weighted vote â†’ Final prediction                                â”‚
â”‚      â†’ agreement: "partial"                                            â”‚
â”‚      â†’ mixed_emotion_flag: true                                        â”‚
â”‚                                                                         â”‚
â”‚  STEP 5: Dynamic Weighting                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â”‚
â”‚    Adjust weights based on confidence:                                 â”‚
â”‚                                                                         â”‚
â”‚    IF text_score > 0.85:                                               â”‚
â”‚      weights = {hubert: 0.30, wav2vec2: 0.20, text: 0.50}             â”‚
â”‚                                                                         â”‚
â”‚    IF hubert_score > 0.70 AND wav2vec2_score > 0.50:                   â”‚
â”‚      weights = {hubert: 0.45, wav2vec2: 0.40, text: 0.15}             â”‚
â”‚                                                                         â”‚
â”‚    DEFAULT (balanced):                                                 â”‚
â”‚      weights = {hubert: 0.40, wav2vec2: 0.35, text: 0.25}             â”‚
â”‚                                                                         â”‚
â”‚  STEP 6: Acoustic Validation                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚    Cross-check prediction with voice characteristics:                  â”‚
â”‚                                                                         â”‚
â”‚    IF emotion = "anger":                                               â”‚
â”‚      AND pitch > 150 Hz AND jitter > 0.02:                             â”‚
â”‚        â†’ Boost confidence +15%                                         â”‚
â”‚      ELSE IF pitch < 100 Hz:                                           â”‚
â”‚        â†’ Reduce confidence -15%                                        â”‚
â”‚                                                                         â”‚
â”‚    IF emotion = "sadness":                                             â”‚
â”‚      AND pitch < 110 Hz AND HNR < 8:                                   â”‚
â”‚        â†’ Boost confidence +10%                                         â”‚
â”‚                                                                         â”‚
â”‚  STEP 7: Confidence Calibration                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚    Different thresholds for neutral vs. strong emotions:               â”‚
â”‚                                                                         â”‚
â”‚    Neutral emotion:                                                    â”‚
â”‚      score > 0.85 â†’ "very_high"                                        â”‚
â”‚      score > 0.65 â†’ "high"                                             â”‚
â”‚      score > 0.45 â†’ "medium"                                           â”‚
â”‚                                                                         â”‚
â”‚    Strong emotion (ang/sad/hap):                                       â”‚
â”‚      score > 0.75 â†’ "very_high"                                        â”‚
â”‚      score > 0.55 â†’ "high"                                             â”‚
â”‚      score > 0.35 â†’ "medium"                                           â”‚
â”‚                                                                         â”‚
â”‚  STEP 8: Context-Aware Mapping                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚    Map all emotions to HuBERT's 4 categories:                          â”‚
â”‚                                                                         â”‚
â”‚    Wav2Vec2 "surprised":                                               â”‚
â”‚      IF pitch > 140 Hz â†’ "happy" (positive surprise)                   â”‚
â”‚      IF jitter > 0.02 â†’ "anger" (shock/alarm)                          â”‚
â”‚      ELSE â†’ "neutral" (mild surprise)                                  â”‚
â”‚                                                                         â”‚
â”‚    Text "fear":                                                        â”‚
â”‚      IF pitch > 140 Hz â†’ "anger" (panic)                               â”‚
â”‚      ELSE â†’ "sadness" (anxiety)                                        â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   REAL-WORLD EXAMPLES                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  Example 1: Clear Anger                                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â”‚
â”‚    Transcript: "I've been waiting for TWO HOURS!"                      â”‚
â”‚    Acoustics: pitch=165 Hz, jitter=0.024, HNR=7.2                      â”‚
â”‚                                                                         â”‚
â”‚    HuBERT:      "ang" (0.88)  â† Detects angry prosody                  â”‚
â”‚    Wav2Vec2:    "angry" (0.82) â† Confirms angry articulation           â”‚
â”‚    DistilRoBERTa: "anger" (0.94) â† Strong angry words                  â”‚
â”‚                                                                         â”‚
â”‚    Result: All agree â†’ "ang" (0.91, very_high confidence) âœ…           â”‚
â”‚                                                                         â”‚
â”‚  Example 2: Sarcasm Detection                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                           â”‚
â”‚    Transcript: "Oh great, just what I needed."                         â”‚
â”‚    Acoustics: pitch=125 Hz, jitter=0.008, HNR=14.5                     â”‚
â”‚                                                                         â”‚
â”‚    HuBERT:      "neu" (0.85)  â† Flat/monotone delivery                 â”‚
â”‚    Wav2Vec2:    "calm" (0.78) â† Restrained articulation                â”‚
â”‚    DistilRoBERTa: "joy" (0.72) â† Words seem positive                   â”‚
â”‚                                                                         â”‚
â”‚    Logic: Audio consensus + calm acoustics                             â”‚
â”‚    Result: "neu" (0.82, high) + sarcasm_flag=true âœ…                   â”‚
â”‚                                                                         â”‚
â”‚  Example 3: Masked Emotion                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚    Transcript: "I'm so frustrated with this!"                          â”‚
â”‚    Acoustics: pitch=155 Hz, jitter=0.020, HNR=8.8                      â”‚
â”‚                                                                         â”‚
â”‚    HuBERT:      "neu" (0.65)  â† Trying to sound calm                   â”‚
â”‚    Wav2Vec2:    "calm" (0.55) â† Voice restrained                       â”‚
â”‚    DistilRoBERTa: "anger" (0.92) â† Words reveal frustration            â”‚
â”‚                                                                         â”‚
â”‚    Logic: Text veto (>0.90) + loud acoustics support it                â”‚
â”‚    Result: "ang" (0.88, high) + text_priority âœ…                       â”‚
â”‚                                                                         â”‚
â”‚  Example 4: Ambiguous/Mixed                                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚    Transcript: "I don't know what to do anymore."                      â”‚
â”‚    Acoustics: pitch=108 Hz, jitter=0.015, HNR=9.5                      â”‚
â”‚                                                                         â”‚
â”‚    HuBERT:      "sad" (0.55)  â† Slight sadness in tone                 â”‚
â”‚    Wav2Vec2:    "neutral" (0.48) â† Unclear articulation                â”‚
â”‚    DistilRoBERTa: "fear" (0.62) â†’ maps to "sad"                        â”‚
â”‚                                                                         â”‚
â”‚    Logic: Weighted vote (sad: 0.55+0.31=0.86 > neutral: 0.17)          â”‚
â”‚    Result: "sad" (0.48, medium) + mixed_emotion_flag=true âœ…           â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                    PHASE 2: HOT-SWAP ARCHITECTURE

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     HOW THE HOT-SWAP WORKS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  PHASE 1 (main.py):                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ pipeline = AnalysisPipeline(                       â”‚               â”‚
â”‚  â”‚     emotion_model_path="superb/hubert-base..."    â”‚  â—„â”€â”€ HF Model â”‚
â”‚  â”‚ )                                                  â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                                         â”‚
â”‚  PHASE 2 (main_phase2.py):                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ pipeline = AnalysisPipeline(                       â”‚               â”‚
â”‚  â”‚     emotion_model_path="./models/clinical_ser..." â”‚  â—„â”€â”€ Local    â”‚
â”‚  â”‚ )                                                  â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                                         â”‚
â”‚  NO OTHER CODE CHANGES NEEDED!                                         â”‚
â”‚  EmotionService automatically loads whichever model path is given      â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                     PHASE 2 WORKFLOW

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ 1. DATA COLLECTION                                           â”‚
  â”‚    Run main.py on many audio files                          â”‚
  â”‚    â†’ Generates JSON outputs                                 â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ 2. DATASET PREPARATION                                       â”‚
  â”‚    python scripts/prepare_dataset.py                        â”‚
  â”‚    â†’ Creates dataset_for_labeling.csv                       â”‚
  â”‚    â†’ Pre-slices all audio segments (optimization!)          â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ 3. HUMAN LABELING                                            â”‚
  â”‚    Open CSV, fill "clinical_label" column                   â”‚
  â”‚    Examples: "anxious", "empathetic", "pain_distress"       â”‚
  â”‚    Save as: dataset_human_labeled.csv                       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ 4. MODEL FINE-TUNING                                         â”‚
  â”‚    python scripts/train_emotion_model.py                    â”‚
  â”‚    â†’ Trains specialized clinical model                      â”‚
  â”‚    â†’ Saves to ./models/clinical_ser_model/                  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ 5. DEPLOY SPECIALIZED MODEL                                  â”‚
  â”‚    python main_phase2.py -i new_audio.mp3                   â”‚
  â”‚    â†’ Uses fine-tuned model automatically                    â”‚
  â”‚    â†’ Outputs clinical emotion labels!                       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                        FILE ORGANIZATION

clinical-audio-pipeline/
â”‚
â”œâ”€â”€ ğŸ“„ main.py ............................ Phase 1 entry point
â”œâ”€â”€ ğŸ“„ main_phase2.py ..................... Phase 2 entry point
â”œâ”€â”€ ğŸ“„ requirements.txt ................... Dependencies
â”œâ”€â”€ ğŸ“„ README.md .......................... Full documentation
â”œâ”€â”€ ğŸ“„ QUICKSTART.md ...................... Quick reference
â”œâ”€â”€ ğŸ“„ PHASE1_SUMMARY.md .................. Development details
â”œâ”€â”€ ğŸ“„ COMPLETION_CHECKLIST.md ............ This checklist
â”‚
â”œâ”€â”€ ğŸ“ pipeline/ .......................... Core system code
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ audio_utilities.py ............. Audio loading/slicing
â”‚   â”œâ”€â”€ ğŸ“„ analysis_pipeline.py ........... Main orchestrator
â”‚   â””â”€â”€ ğŸ“ services/
â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”œâ”€â”€ ğŸ“„ diarization_service.py ..... Speaker identification
â”‚       â”œâ”€â”€ ğŸ“„ asr_service.py ............. Transcription
â”‚       â”œâ”€â”€ ğŸ“„ emotion_service.py ......... Emotion recognition
â”‚       â””â”€â”€ ğŸ“„ acoustic_service.py ........ Acoustic features
â”‚
â”œâ”€â”€ ğŸ“ scripts/ ........................... Phase 2 utilities
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ prepare_dataset.py ............. Create training dataset
â”‚   â””â”€â”€ ğŸ“„ train_emotion_model.py ......... Fine-tune model
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ ğŸ“ input/ ......................... Your audio files HERE
â”‚   â””â”€â”€ ğŸ“ output/ ........................ JSON results go here
â”‚
â””â”€â”€ ğŸ“ models/ ............................ Fine-tuned models


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                     KEY ARCHITECTURAL DECISIONS

1. SERVICE-ORIENTED ARCHITECTURE
   âœ“ Each service is independent and reusable
   âœ“ Single responsibility principle
   âœ“ Easy to test and maintain

2. LOAD ONCE, USE MANY
   âœ“ All models loaded at initialization
   âœ“ Reused for all segments
   âœ“ Massive performance improvement

3. HOT-SWAPPABLE DESIGN
   âœ“ Emotion model as configurable parameter
   âœ“ No code changes between Phase 1 and 2
   âœ“ Easy to experiment with different models

4. FAIL-SAFE OPERATIONS
   âœ“ Individual service failures don't crash pipeline
   âœ“ Graceful degradation
   âœ“ Informative error messages

5. OPTIMIZATION FOR TRAINING
   âœ“ Pre-slice audio segments
   âœ“ Avoid I/O bottleneck during training
   âœ“ Fast dataset iteration


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                         QUICK COMMANDS

# Install
pip install -r requirements.txt

# Set Token (PowerShell)
$env:HF_TOKEN="your_token_here"

# Run Phase 1
python main.py -i ./data/input/audio.mp3

# Prepare Phase 2 Dataset
python scripts/prepare_dataset.py

# Train Phase 2 Model
python scripts/train_emotion_model.py

# Run Phase 2
python main_phase2.py -i ./data/input/audio.mp3


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                      SYSTEM READY! ğŸš€

All Phase 1 requirements completed.
Install dependencies and start analyzing audio!


